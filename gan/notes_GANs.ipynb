{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN\n",
    "\n",
    "We have this generator and discriminator models.\n",
    "\n",
    "The generator role is to produce realistic image (or data) from random noise. The discriminator role is to tells wether the image (or data) it receives is fake or real.\n",
    "\n",
    "To produce fake data, the generator is shown a lot of realistic images and is asked to produces more images that come from the same probability distribution. To do that, we use an approximation, the second model Discriminator that is a regular neural net classifier.\n",
    "\n",
    "They compete to each other, and by trying to fool the discriminator, the generator is actually learning to produce very realistic data over time. Over time the discriminator also gets better at detecting fake data so this ongoing competition is what makes good results.\n",
    "\n",
    "## Game Theory\n",
    "\n",
    "It is a branch of maths use to model competitions strategies where payoff and changes in strategies can help understanding how to optimize and reach an equilibrium. The equilibrium happens when neither player can improve their strategy without changing the other player strategy.\n",
    "\n",
    "You want to find a point that is the local **maximum** for the discriminator. It happens for the disciminator when it accurately estimates the probability that the input is real rather than fake. When the equilibrium happens the generator density is equal to the true data density, and therefore the discriminator should always input $\\frac{1}{2}$ as it cannot detect the difference between true and fake anymore.\n",
    "\n",
    "Unfortunately, equilibrium might exist, but are only get close to it in real.\n",
    "\n",
    "## Tips for training GAN\n",
    "\n",
    "1. Use Leaky Relu activation.\n",
    "2. Use Hyperbolic Tan output for the generator, ranging from -1 to +1.\n",
    "3. We use a sigmoid function to have a probability as an output of the discriminator.\n",
    "4. Adam optimizer is a good choice for the generator and discriminator.\n",
    "5. Use BCE Loss criterion for the discriminator, Binary Cross Entropy (nn.BCEWithLogitsLoss(logits, labels\\*0.9). Multiplying by 0.9 the label is part of the smoothing lable strategy that is used to regularized normal classifiers. It helps the discriminator to generalize better.\n",
    "6. Use BCE Loss criterion for the generator, nn.BCEWithLogitsLoss(logits, flipped_labels).\n",
    "\n",
    "## Scaling GAN to work on large images\n",
    "\n",
    "The main trick is to use Convolutional Networks. For the input of the generator we usually use a random vector Z. The problem is that a convolutional expect to get a 4D tensor, one axis for different examples in the mini-batch, one axis for the features, and axis for the width and height. To transform the vector Z we need to reshape up near the start of the generator. The idea is to actually do the opposite as what a classic CNN is doing. Instead of going from and image with features and ending up with a very deep small image, we want to start with a deep vector Z and up scaling it until having an image in the output.\n",
    "\n",
    "<img src=\"img/reshapeup.png\" width=30% />\n",
    "\n",
    "You want to use Batch Normalization on each layers except the output layer of the generator and the discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional GAN\n",
    "\n",
    "## Introduction\n",
    "\n",
    "<img src=\"img/GANs.png\" width=60% />\n",
    "\n",
    "The main focus of a GAN model is to generate data from scratch, mostly images but it can be anything, like sound. Two networks are part of a DCGAN, a **generator** and a **discriminator**. The role of the generator is to generate random data, but it alone it would be useless. This is where the discriminator come in play. It will tell if the generated data looks real or fake by comparing it to real data. By training the model with real data it can become really good at generating data that looks real.\n",
    "\n",
    "## Discriminator\n",
    "\n",
    "<img src='img/discriminatorfull.png' width=55% />\n",
    "\n",
    "There are no Max Pooling layer in the discriminator conv net, the downsampling is entirely made using convolutional layers with stride=2.\n",
    "\n",
    "If the convolutional kernel is moving 2 pixels by 2 pixels (stride of 2) then it will output an image half the size of the input image.\n",
    "\n",
    "After each convolutional layer there is a **leaky ReLU activation** and a **batch normalization** (so the **mean = 0** and **variance = 1**). This normalization step helps the network train faster and reduces problems due to poor parameter initialization.\n",
    "\n",
    "<div style=\"display: flex;\">\n",
    "    <div style=\"margin: auto;\">\n",
    "        <img src='img/convlayerkernel2.png' style=\"max-width: 200px;\"/>\n",
    "    </div>\n",
    "    <div style=\"margin: auto;\">\n",
    "        <img src='img/leakyrelu.png' style=\"max-width: 200px;\"/>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "## Generator\n",
    "\n",
    "A generator is here to \n",
    "<img src=\"img/generatorfull.png\" width=60% />\n",
    "\n",
    "With transposed convolutional layer you go from narrow and deep inputs like vectors to wide and flat outputs like image.\n",
    "By using a layer with a stride of 2 it will upsample the output image twice the size the input image.\n",
    "\n",
    "\n",
    "<div style=\"display: flex;\">\n",
    "    <div style=\"margin: auto;\">\n",
    "        <img src=\"img/transposedconvlayer.png\" style=\"max-width: 400px;\"/>\n",
    "    </div>\n",
    "    <div style=\"margin: auto;\">\n",
    "        <img src=\"img/upsamplestride2.png\" style=\"max-width: 400px;\"/>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "## What is Batch Normalization?\n",
    "\n",
    "Instead of normalizing only the inputs of the network, we normalize the inputs to every layer _within_ the network.\n",
    "We use the _mean_ and _standard deviation_ (or variance) of the values in the current batch.\n",
    "The normalization of the output from a previous layer happens by subtracting the batch mean and dividing by the batc standard deviation.\n",
    "\n",
    "\n",
    "Getting the mean and variance\n",
    "\n",
    "We represent the average as $\\mu_B$\n",
    "$$\\mu_B$$\n",
    "\n",
    "which is simply the sum of all of the values, $x_i$ divided by the number of values, $m$.\n",
    "\n",
    "$$\\mu_B \\leftarrow \\frac{1}{m}\\sum_{i=1}^m x_i$$\n",
    "\n",
    "We then need to calculate the variance, or mean squared deviation, represented as\n",
    "$$\\sigma_{B}^{2}$$\n",
    "\n",
    "For each value x_i, we subtract the average value (calculated earlier as mu_B), which gives us what's called the \"deviation\" for that value. We square the result to get the squared deviation. Sum up the results of doing that for each of the values, then divide by the number of values, again $m$, to get the average, or mean, squared deviation.\n",
    "\n",
    "$$\\sigma_{B}^{2} \\leftarrow \\frac{1}{m}\\sum_{i=1}^m (x_i - \\mu_B)^2$$\n",
    "\n",
    "Once we have the mean and variance, we can use them to normalize the values with the following equation. For each value, it subtracts the mean and divides by the (almost) standard deviation.\n",
    "\n",
    "$$\\hat{x_i} \\leftarrow \\frac{x_i - \\mu_B}{\\sqrt{\\sigma_{B}^{2} + \\epsilon}}$$\n",
    " \n",
    "I said \"almost\" standard deviation because the real standard deviation for the batch is calculated by\n",
    "$$\\sqrt{\\sigma_{B}^{2}}$$\n",
    "\n",
    "but the above formula adds the term epsilon before taking the square root. The epsilon can be any small, positive constant, ex. the value 0.001. It is there partially to make sure we don't try to divide by zero, but it also acts to increase the variance slightly for each batch.\n",
    "\n",
    "Why add this extra value and mimic an increase in variance? Statistically, this makes sense because even though we are normalizing one batch at a time, we are also trying to estimate the population distribution â€“ the total training set, which itself is an estimate of the larger population of inputs your network wants to handle. The variance of a population is typically higher than the variance for any sample taken from that population, especially when you use a small sample size (a small sample is more likely to include values near the peak of a population distribution), so increasing the variance a little bit for each batch helps take that into account.\n",
    "\n",
    "At this point, we have a normalized value, represented as\n",
    "$$\\hat{x_i}$$\n",
    "\n",
    "But rather than use it directly, we multiply it by a gamma value, and then add a beta value. Both gamma and beta are learnable parameters of the network and serve to scale and shift the normalized value, respectively. Because they are learnable just like weights, they give your network some extra knobs to tweak during training to help it learn the function it is trying to approximate.\n",
    "\n",
    "$$y_i \\leftarrow \\gamma \\hat{x_i} + \\beta$$\n",
    "\n",
    "We now have the final batch-normalized output of our layer, which we would then pass to a non-linear activation function like sigmoid, tanh, ReLU, Leaky ReLU, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To add batch normalization layers to a PyTorch model:\n",
    "\n",
    "* You add batch normalization to layers inside the__init__ function.\n",
    "* Layers with batch normalization do not include a bias term. So, for linear or convolutional layers, you'll need to set bias=False if you plan to add batch normalization on the outputs.\n",
    "* You can use PyTorch's [BatchNorm1d] function to handle the math on linear outputs or [BatchNorm2d] for 2D outputs, like filtered images from convolutional layers.\n",
    "* You add the batch normalization layer before calling the activation function, so it always goes layer > batch norm > activation.\n",
    "\n",
    "Finally, when you tested your model, you set it to .eval() mode, which ensures that the batch normalization layers use the populationrather than the batch mean and variance (as they do during training).\n",
    "\n",
    "**Benefits of Batch Normalization**\n",
    "1. Networks train faster\n",
    "2. Allows higher learning rates\n",
    "3. Makes weights easier to initialize\n",
    "4. Makes more activation functions viable\n",
    "5. Simplifies the creation of deeper networks\n",
    "6. Provides a bit of regularization\n",
    "7. May give a better results overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cycle GAN and Pix2Pix\n",
    "\n",
    "They can generate a realistic picture of a cat from a hand drawing, or transform a real time video of a horse into a zebra (image to image translation), pretty neat right ?\n",
    "\n",
    "## Applications\n",
    "\n",
    "The idea is to provide an image in input, apply a transformation and have an image in output.\n",
    "The other image application are semantic segmentation, or labeling all the different things in an image, and edge detection.\n",
    "\n",
    "<img src=\"img/imgtransfo.png\" width=80% />\n",
    "\n",
    "You can also do automatic colorization, or make an image more sharper.\n",
    "\n",
    "<img src=\"img/imgtransfo2.png\" width=80% />\n",
    "\n",
    "## Pix2Pix\n",
    "For image to image translation they use an image as input, then use a encoder decoder to produce an new desired image as output.\n",
    "\n",
    "<img src=\"img/pix2pix.png\" width=60% />\n",
    "\n",
    "Quick recap on encoder / decoder : \n",
    "\n",
    "The encoder tries to compress and encode an image to a smaller feature representation :\n",
    "\n",
    "<img src=\"img/encoder.png\" width=60% />\n",
    "\n",
    "The decoder will look at features level representation and uses that to generate a new realistic output image :\n",
    "\n",
    "<img src=\"img/decoder.png\" width=60% />\n",
    "\n",
    "We then link the output of this encoder / decoder to a discriminator which will say if this image is real or fake as usual.\n",
    "\n",
    "The discriminator will look at pairs of images. It labels a pair of images as real or fake. This way the network learns how to create a mapping between an input image (a sketch for example) and a real target image (a real image of the sketch).\n",
    "\n",
    "<img src=\"img/pix2pixapplication.png\" width=60% />\n",
    "\n",
    "The generator wants the error of the discriminator to be large, it want the input and the generated image to be classified as real. With the discriminator also learning to classify better, the quality of the generated image is constantly getting better and better.\n",
    "\n",
    "The discriminator is acting as the loss function, and this conditional on both input and output images to the generator is why it is called a Conditional GAN.\n",
    "\n",
    "## Cycle GAN\n",
    "\n",
    "It is difficult to always have paired labeled data. It is hard to ask a zebra to do the same pose as a horse in the same environment for example. How to learn from unpaired data then ? We want to find a mapping G that tries its best to map from an image X to an image Y.\n",
    "\n",
    "The risk of unpaired data while using a encoder decoder is the **mode collapse**.\n",
    "\n",
    "After doing a mapping from X to Y, we do the inverse mapping from Y to X of the generated image and we can then compare the original image and cycled generated image to measure the difference between those two. The goal is to have no difference in the original image if you do a mapping and then its inverse mapping.\n",
    "\n",
    "\n",
    "<img src=\"img/cycleganexample.png\" width=50% />\n",
    "\n",
    "In this example if we translate from French to English, and then from English back to French we should have the same original sentence.\n",
    "\n",
    "$$G_{YtoX}(G_{XtoY}(x)) \\approx x$$\n",
    "\n",
    "### Cycle Consistency Loss\n",
    "\n",
    "<img src=\"img/consistencyloss.png\" width=60% />\n",
    "\n",
    "The complete loss in a Cycle Gan is $$L_Y + L_X + \\lambda L_{cyc}$$\n",
    "\n",
    "It is the sum of the adversarial losses and the cycle consistency loss. Lambda is the rate value that controls the rate of importance of these terms.\n",
    "\n",
    "A CycleGAN will product only one mapping given an input image. The research is exploring ways to produce multiple styles from one input with networks like Paired CyclGAN, Cros-domain models or StarGAN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GANs applications\n",
    "\n",
    "Medium article about a list of cool GANs applications\\\n",
    "https://medium.com/@jonathan_hui/gan-some-cool-applications-of-gans-4c9ecca35900\n",
    "\n",
    "Tulips generator\\\n",
    "https://www.fastcompany.com/90237233/this-ai-dreams-in-tulips\n",
    "\n",
    "Semi-supervised learning video explanation made by Ian Goodfellow\\\n",
    "https://www.youtube.com/watch?v=_LRpHPxZaX0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
